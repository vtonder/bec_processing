**********************
5) MPI + mean analysis
**********************
- Start timer before array creation and read in of data
- Conduct processing for both mean and sum squares
- Stop timer
- Analysis conducted on x pol 1569 h5 file

cores | num chunks processed | total data len | processing time per processor (unit s) | total processing time (averaged over  times) 
---------------------------------------------------------------------------------------------------------
5     | 2919.0               | 239124480      | 2951.9122191639617                     | 3034.3588042259216  
10    | 1459.0               | 239042560      | 1477.788330548443                      | 1574.2632755279542
15    | 973.0                | 239124480      | 1003.9506793580949                     | 1047.1665592193604
20    | 729.0                | 238878720      | 759.8343786997721                      | 789.898957490921
25    | 583.0                | 238796800      | 626.7423422709107                      | 709.3646445274353 
30    | 486.0                | 238878720      | 541.3413198925555                      | 663.7875745773315 
35    | 417.0                | 239124480      | 482.35602218285203                     | 643.1528521537781
40    | 364.0                | 238551040      | 593.6757857976481                      | 576.8024142742157 
45    | 324.0                | 238878720      | 1745.7610048977658                     | 537.296351480484

****************
4) mean analysis
****************
- code that read in everything into cache using elipses data = file['Data/bf_raw'][...] and reading re and im separately took ~ 2 hours.
- not reading into cache and conducting IO directly to disk and operating on re and im at the same time, took 5847.446479797363 s
- adding rdcc_nbytes=1024*128 to the h5py.File() instantiation: 5809.016752719879 s
- adding rdcc_nbytes= 0 took: 5696.401374340057
 

**************************
3) Bispectrum computation
**************************
Processing 39 records of 1024 samples each from gps_l2 frequency channel of vela y pol data (smallest dataset)
- Direct computation of bispectrum
Calculating entire I quadrant from equation: 2.157341957092285
Calculating only k1 <= k2 in I quadrant: 1.1635143756866455
Calculating entire I quadrant using symmetry: 1.4344885349273682

- only calculate triangle region in direct bispectrum because it's the most efficient  

*******************************************
2) On data reading in data
*******************************************
- seems to be faster to slice from hdf5 and operate directly on them

2.1) File: 1604641234 (51G) x pol
- Using data = vela_x['Data/bf_raw'][()]
Number of data points 26214400
read in data t: 1627025748.837136
done reading in data:  72.8339593410492
fold data 1627025821.6711824
done fold data 369.6821482181549

- Using data = vela_x['Data/bf_raw'][...]
Number of data points 26214400
read in data t: 1627027057.005228
done reading in data:  29.75274634361267
fold data 1627027086.7581153
done fold data 364.635977268219

- Using data = vela_x['Data/bf_raw'][...] + , driver="core") enabled when creating hdf5
Number of data points 26214400
read in data t: 1627027666.5861235
done reading in data:  27.73506474494934
fold data 1627027694.321418
done fold data 377.5340988636017

2.2) File: 1604641569 (485G) x pol
Using elipses [...]
took : 1008.7704093456268 s 
Using [()]
took : 6960.859574556351 s

Number of data points 252755968
read in data t: 1627030151.102644
done reading in data:  2310.688520669937

Number of data points 252755968
read in data t: 1627047244.962056
done reading in data:  4997.647198915482
dedisperse data t: 1627052242.702763
done dedispersing data:  35969.85751581192
fold data 1627088234.8089302
done fold data 17575.614918231964

Number of data points 252755968
read in data t: 1627115858.0413966
done reading in data:  2618.5901551246643
dedisperse data t: 1627118476.805828
done dedispersing data:  1102.8677883148193
fold data 1627119582.6673527
done fold data 3984.2967970371246

***************************************
1) On dummy data sets using tut_dask
***************************************
using numpy:
    create array
    took  0.001337289810180664
    fold
    took  0.0074498653411865234
    dedisperse
    took  0.00017786026000976562

dask array:
    create array
    took  0.008998632431030273
    fold
    took  5.9367358684539795
    dedisperse
    took  1.4565298557281494
    calling compute
    took  28.615339756011963

 def acc_vela():
   ...:     global val, num_data_points, vela_samples_T
   ...:     for i in 3381:
   ...:         start = int(i*vela_samples_T)
   ...:         end = start + vela_samples_T
   ...:         if end >= num_data_points:
   ...:             break;
   ...:         val += f[:,start:end,:].astype(np.float)
